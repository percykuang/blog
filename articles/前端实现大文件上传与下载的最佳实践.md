@date: 2022-05-23
@tag: [react,业务场景]

## 背景介绍

在Web应用开发中，处理大文件的上传和下载是一个常见而棘手的问题。传统的文件传输方式在处理大文件时往往会遇到性能瓶颈、超时错误和糟糕的用户体验。本文将深入探讨前端实现大文件上传与下载的最佳实践，包括文件切片、断点续传、进度监控等关键技术。

## 一、大文件上传的挑战

传统文件上传面临的主要问题：

1. 请求超时：大文件上传耗时长，容易触发服务器或浏览器的超时限制
2. 内存占用：一次性加载大文件会占用大量内存
3. 上传失败无法恢复：网络波动导致上传失败时需要重新上传整个文件
4. 用户体验差：缺乏进度反馈，用户无法了解上传状态

## 二、文件切片上传技术

### 2.1 基本原理

文件切片上传的核心思想是将大文件分割成多个小块（切片），分别上传这些切片，最后在服务器端合并。这种方式有以下优势：

- 单个请求体积小，不易超时
- 可以并发上传多个切片，提高上传速度
- 支持断点续传，提升用户体验
- 便于实现上传进度的精确计算

### 2.2 前端实现

#### 2.2.1 文件切片

```js
/**
 * 将文件切片
 * @param {File} file - 要上传的文件
 * @param {number} chunkSize - 切片大小(bytes)
 * @returns {Array} 切片数组
 */
function createFileChunks(file, chunkSize = 1024 * 1024 * 5) {
  const chunks = [];
  let cur = 0;
  while (cur < file.size) {
    chunks.push(file.slice(cur, cur + chunkSize));
    cur += chunkSize;
  }
  return chunks;
}
```

#### 2.2.2 计算文件唯一标识

为了实现断点续传，需要为每个文件生成唯一标识：

```js
/**
 * 计算文件的MD5值作为唯一标识
 * @param {File} file - 文件对象
 * @returns {Promise<string>} MD5哈希值
 */
async function calculateFileMD5(file) {
  return new Promise((resolve, reject) => {
    const reader = new FileReader();
    reader.readAsArrayBuffer(file);
    reader.onload = (e) => {
      const buffer = e.target.result;
      const spark = new SparkMD5.ArrayBuffer();
      spark.append(buffer);
      const md5 = spark.end();
      resolve(md5);
    };
    reader.onerror = reject;
  });
}
```

#### 2.2.3 上传切片

```js
/**
 * 上传单个切片
 * @param {Blob} chunk - 文件切片
 * @param {number} index - 切片索引
 * @param {string} fileId - 文件唯一标识
 * @param {string} fileName - 文件名
 * @returns {Promise}
 */
async function uploadChunk(chunk, index, fileId, fileName) {
  const formData = new FormData();
  formData.append('chunk', chunk);
  formData.append('index', index);
  formData.append('fileId', fileId);
  formData.append('fileName', fileName);

  return axios.post('/upload/chunk', formData, {
    headers: {
      'Content-Type': 'multipart/form-data',
    },
    // 上传进度监控
    onUploadProgress: (e) => {
      // 可以在这里更新每个切片的上传进度
    },
  });
}
```

#### 2.2.4 并发控制

为了避免过多的并发请求导致浏览器或服务器崩溃，需要控制并发数：

```js
/**
 * 控制并发上传
 * @param {Array} chunks - 切片数组
 * @param {string} fileId - 文件唯一标识
 * @param {string} fileName - 文件名
 * @param {number} concurrency - 并发数
 * @returns {Promise}
 */
async function uploadChunksWithConcurrency(chunks, fileId, fileName, concurrency = 3) {
  const pool = []; // 并发池
  const results = []; // 存储所有上传结果

  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];

    // 创建上传任务
    const task = async () => {
      const result = await uploadChunk(chunk, i, fileId, fileName);
      results[i] = result;
      return result;
    };

    // 将任务加入并发池
    const promise = task();
    pool.push(promise);

    // 当并发数达到限制时，等待一个任务完成
    if (pool.length >= concurrency) {
      await Promise.race(pool);
      // 移除已完成的任务
      const index = await Promise.race(
        pool.map(async (p, index) => {
          try {
            await p;
            return index;
          } catch (e) {
            return -1;
          }
        })
      );
      if (index !== -1) {
        pool.splice(index, 1);
      }
    }
  }

  // 等待所有任务完成
  await Promise.all(pool);
  return results;
}
```

#### 2.2.5 合并请求

所有切片上传完成后，通知服务器合并文件：

```js
/**
 * 请求合并切片
 * @param {string} fileId - 文件唯一标识
 * @param {string} fileName - 文件名
 * @param {number} totalChunks - 切片总数
 * @returns {Promise}
 */
async function mergeChunks(fileId, fileName, totalChunks) {
  return axios.post('/upload/merge', {
    fileId,
    fileName,
    totalChunks,
  });
}
```

#### 2.2.6 断点续传实现

断点续传需要记录已上传的切片，在上传前检查：

```js
/**
 * 获取已上传的切片
 * @param {string} fileId - 文件唯一标识
 * @returns {Promise<Array>} 已上传的切片索引数组
 */
async function getUploadedChunks(fileId) {
  const response = await axios.get(`/upload/chunks?fileId=${fileId}`);
  return response.data.uploadedChunks || [];
}

/**
 * 实现断点续传
 * @param {File} file - 要上传的文件
 */
async function resumableUpload(file) {
  // 计算文件MD5作为唯一标识
  const fileId = await calculateFileMD5(file);

  // 获取文件已上传的切片
  const uploadedChunks = await getUploadedChunks(fileId);

  // 切割文件
  const chunks = createFileChunks(file);

  // 过滤出未上传的切片
  const remainingChunks = chunks.filter((_, index) => !uploadedChunks.includes(index));

  // 上传剩余切片
  await uploadChunksWithConcurrency(remainingChunks, fileId, file.name);

  // 合并文件
  await mergeChunks(fileId, file.name, chunks.length);

  return { success: true, fileId };
}
```

### 2.3 完整的 React 组件示例

下面是一个完整的React组件，实现了大文件切片上传、断点续传和进度显示：

```jsx
import React, { useCallback, useState } from 'react';

import axios from 'axios';
import SparkMD5 from 'spark-md5';

const FileUploader = () => {
  const [selectedFile, setSelectedFile] = useState(null);
  const [uploadProgress, setUploadProgress] = useState(0);
  const [uploading, setUploading] = useState(false);
  const [uploadedChunks, setUploadedChunks] = useState([]);

  // 文件选择处理
  const handleFileChange = (e) => {
    const file = e.target.files[0];
    if (file) {
      setSelectedFile(file);
      setUploadProgress(0);
    }
  };

  // 计算文件MD5
  const calculateFileMD5 = useCallback(async (file) => {
    return new Promise((resolve, reject) => {
      const blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;
      const chunkSize = 2097152; // 2MB
      const chunks = Math.ceil(file.size / chunkSize);
      let currentChunk = 0;
      const spark = new SparkMD5.ArrayBuffer();
      const fileReader = new FileReader();

      fileReader.onload = (e) => {
        spark.append(e.target.result);
        currentChunk++;

        if (currentChunk < chunks) {
          loadNext();
        } else {
          const md5 = spark.end();
          resolve(md5);
        }
      };

      fileReader.onerror = reject;

      function loadNext() {
        const start = currentChunk * chunkSize;
        const end = Math.min(start + chunkSize, file.size);
        fileReader.readAsArrayBuffer(blobSlice.call(file, start, end));
      }

      loadNext();
    });
  }, []);

  // 创建文件切片
  const createFileChunks = useCallback((file, chunkSize = 1024 * 1024 * 5) => {
    const chunks = [];
    let cur = 0;
    while (cur < file.size) {
      chunks.push(file.slice(cur, cur + chunkSize));
      cur += chunkSize;
    }
    return chunks;
  }, []);

  // 获取已上传的切片
  const getUploadedChunks = useCallback(async (fileId) => {
    try {
      const response = await axios.get(`/upload/chunks?fileId=${fileId}`);
      return response.data.uploadedChunks || [];
    } catch (error) {
      console.error('获取已上传切片失败:', error);
      return [];
    }
  }, []);

  // 上传单个切片
  const uploadChunk = useCallback(
    async (chunk, index, fileId, fileName, totalChunks) => {
      const formData = new FormData();
      formData.append('chunk', chunk);
      formData.append('index', index);
      formData.append('fileId', fileId);
      formData.append('fileName', fileName);
      formData.append('totalChunks', totalChunks);

      try {
        await axios.post('/upload/chunk', formData, {
          headers: {
            'Content-Type': 'multipart/form-data',
          },
        });

        // 更新已上传的切片
        setUploadedChunks((prev) => [...prev, index]);

        // 更新总进度
        setUploadProgress((prevProgress) => {
          const newProgress = Math.round(((uploadedChunks.length + 1) / totalChunks) * 100);
          return Math.max(prevProgress, newProgress);
        });

        return { success: true, index };
      } catch (error) {
        console.error(`切片 ${index} 上传失败:`, error);
        return { success: false, index };
      }
    },
    [uploadedChunks]
  );

  // 合并切片
  const mergeChunks = useCallback(async (fileId, fileName, totalChunks) => {
    try {
      await axios.post('/upload/merge', {
        fileId,
        fileName,
        totalChunks,
      });
      return true;
    } catch (error) {
      console.error('合并切片失败:', error);
      return false;
    }
  }, []);

  // 开始上传
  const startUpload = useCallback(async () => {
    if (!selectedFile) {
      alert('请先选择文件');
      return;
    }

    setUploading(true);

    try {
      // 计算文件MD5
      const fileId = await calculateFileMD5(selectedFile);

      // 获取已上传的切片
      const uploadedChunksData = await getUploadedChunks(fileId);
      setUploadedChunks(uploadedChunksData);

      // 创建切片
      const chunks = createFileChunks(selectedFile);
      const totalChunks = chunks.length;

      // 更新初始进度
      setUploadProgress(Math.round((uploadedChunksData.length / totalChunks) * 100));

      // 上传未完成的切片
      const uploadPromises = [];

      for (let i = 0; i < totalChunks; i++) {
        if (!uploadedChunksData.includes(i)) {
          uploadPromises.push(uploadChunk(chunks[i], i, fileId, selectedFile.name, totalChunks));
        }
      }

      // 等待所有切片上传完成
      await Promise.all(uploadPromises);

      // 合并切片
      const mergeResult = await mergeChunks(fileId, selectedFile.name, totalChunks);

      if (mergeResult) {
        alert('文件上传成功!');
        setUploadProgress(100);
      } else {
        alert('文件合并失败，请重试');
      }
    } catch (error) {
      console.error('上传过程中出错:', error);
      alert('上传失败，请重试');
    } finally {
      setUploading(false);
    }
  }, [selectedFile, calculateFileMD5, getUploadedChunks, createFileChunks, uploadChunk, mergeChunks]);

  // 暂停上传
  const pauseUpload = useCallback(() => {
    // 实际实现中可以取消正在进行的请求
    setUploading(false);
    alert('上传已暂停，您可以稍后继续');
  }, []);

  return (
    <div className="file-uploader">
      <h2>大文件分片上传示例</h2>

      <div className="upload-container">
        <input type="file" onChange={handleFileChange} disabled={uploading} />

        {selectedFile && (
          <div className="file-info">
            <p>文件名: {selectedFile.name}</p>
            <p>文件大小: {(selectedFile.size / 1024 / 1024).toFixed(2)} MB</p>
          </div>
        )}

        <div className="progress-container">
          <div className="progress-bar" style={{ width: `${uploadProgress}%` }}></div>
          <span className="progress-text">{uploadProgress}%</span>
        </div>

        <div className="button-group">
          <button onClick={startUpload} disabled={!selectedFile || uploading}>
            {uploadedChunks.length > 0 ? '继续上传' : '开始上传'}
          </button>

          {uploading && <button onClick={pauseUpload}>暂停上传</button>}
        </div>
      </div>
    </div>
  );
};

export default FileUploader;
```

## 三、大文件下载技术

### 3.1 传统下载的问题

传统的文件下载方式存在以下问题：

1. 无法显示下载进度：用户无法了解下载状态
2. 下载中断无法恢复：网络波动导致下载失败时需要重新下载
3. 大文件下载耗时长：用户体验差

### 3.2 流式下载与切片下载

#### 3.2.1 使用 Blob 和 URL.createObjectURL

```js
/**
 * 基本的文件下载函数
 * @param {string} url - 文件下载地址
 * @param {string} filename - 保存的文件名
 */
async function downloadFile(url, filename) {
  try {
    const response = await fetch(url);
    const blob = await response.blob();
    const objectUrl = URL.createObjectURL(blob);

    const link = document.createElement('a');
    link.href = objectUrl;
    link.download = filename;
    document.body.appendChild(link);
    link.click();

    // 清理
    document.body.removeChild(link);
    URL.revokeObjectURL(objectUrl);
  } catch (error) {
    console.error('下载失败:', error);
  }
}
```

#### 3.3.2 带进度监控的下载

```js
/**
 * 带进度监控的文件下载
 * @param {string} url - 文件下载地址
 * @param {string} filename - 保存的文件名
 * @param {Function} onProgress - 进度回调函数
 */
async function downloadFileWithProgress(url, filename, onProgress) {
  try {
    const response = await fetch(url);

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    // 获取文件大小
    const contentLength = response.headers.get('content-length');
    const total = parseInt(contentLength, 10);

    // 创建可读流
    const reader = response.body.getReader();

    // 接收数据块
    let receivedLength = 0;
    const chunks = [];

    while (true) {
      const { done, value } = await reader.read();

      if (done) {
        break;
      }

      chunks.push(value);
      receivedLength += value.length;

      // 报告进度
      if (onProgress) {
        onProgress(receivedLength, total);
      }
    }

    // 合并数据块
    const chunksAll = new Uint8Array(receivedLength);
    let position = 0;
    for (const chunk of chunks) {
      chunksAll.set(chunk, position);
      position += chunk.length;
    }

    // 创建Blob并下载
    const blob = new Blob([chunksAll]);
    const objectUrl = URL.createObjectURL(blob);

    const link = document.createElement('a');
    link.href = objectUrl;
    link.download = filename;
    document.body.appendChild(link);
    link.click();

    // 清理
    document.body.removeChild(link);
    URL.revokeObjectURL(objectUrl);
  } catch (error) {
    console.error('下载失败:', error);
  }
}
```

#### 3.3.3 切片下载

对于超大文件，可以实现切片下载：

```js
/**
 * 切片下载大文件
 * @param {string} url - 文件基础URL
 * @param {string} filename - 保存的文件名
 * @param {number} chunkSize - 切片大小(bytes)
 * @param {number} totalSize - 文件总大小
 * @param {Function} onProgress - 进度回调函数
 */
async function downloadLargeFile(url, filename, chunkSize, totalSize, onProgress) {
  // 计算切片数量
  const chunks = Math.ceil(totalSize / chunkSize);
  const chunksData = [];

  // 获取本地存储中的下载进度
  const storageKey = `download_${url}_${filename}`;
  const storedData = localStorage.getItem(storageKey);
  let downloadedChunks = [];

  if (storedData) {
    try {
      const parsed = JSON.parse(storedData);
      downloadedChunks = parsed.downloadedChunks || [];
      chunksData.push(...(parsed.chunksData || []));
    } catch (e) {
      console.error('解析存储的下载进度失败:', e);
      downloadedChunks = [];
    }
  }

  // 计算已下载的大小
  let downloadedSize = downloadedChunks.length * chunkSize;
  if (onProgress) {
    onProgress(downloadedSize, totalSize);
  }

  // 下载未完成的切片
  for (let i = 0; i < chunks; i++) {
    // 跳过已下载的切片
    if (downloadedChunks.includes(i)) {
      continue;
    }

    const start = i * chunkSize;
    const end = Math.min(start + chunkSize - 1, totalSize - 1);

    try {
      const response = await fetch(url, {
        headers: {
          Range: `bytes=${start}-${end}`,
        },
      });

      if (!response.ok && response.status !== 206) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const buffer = await response.arrayBuffer();
      chunksData[i] = new Uint8Array(buffer);

      // 更新下载进度
      downloadedChunks.push(i);
      downloadedSize += buffer.byteLength;

      // 保存下载进度到本地存储
      localStorage.setItem(
        storageKey,
        JSON.stringify({
          downloadedChunks,
          totalChunks: chunks,
        })
      );

      // 报告进度
      if (onProgress) {
        onProgress(downloadedSize, totalSize);
      }
    } catch (error) {
      console.error(`下载切片 ${i} 失败:`, error);
      // 继续下载下一个切片，不中断整个过程
    }
  }

  // 合并所有切片
  const completeFile = new Uint8Array(totalSize);
  let position = 0;

  for (let i = 0; i < chunks; i++) {
    const chunk = chunksData[i];
    completeFile.set(chunk, position);
    position += chunk.byteLength;
  }

  // 创建Blob并下载
  const blob = new Blob([completeFile]);
  const objectUrl = URL.createObjectURL(blob);

  const link = document.createElement('a');
  link.href = objectUrl;
  link.download = filename;
  document.body.appendChild(link);
  link.click();

  // 清理
  document.body.removeChild(link);
  URL.revokeObjectURL(objectUrl);

  // 清除本地存储中的下载进度
  localStorage.removeItem(storageKey);
}
```

### 3.3 React 组件实现文件下载

下面是一个React组件，实现了带进度条的文件下载功能：

```jsx
import React, { useCallback, useState } from 'react';

const FileDownloader = ({ url, filename, fileSize }) => {
  const [downloadProgress, setDownloadProgress] = useState(0);
  const [isDownloading, setIsDownloading] = useState(false);
  const [isPaused, setIsPaused] = useState(false);

  // 带进度监控的下载
  const downloadWithProgress = useCallback(async () => {
    setIsDownloading(true);
    setIsPaused(false);

    try {
      const response = await fetch(url);

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      // 获取文件大小
      const contentLength = response.headers.get('content-length');
      const total = parseInt(contentLength, 10) || fileSize;

      // 创建可读流
      const reader = response.body.getReader();

      // 接收数据块
      let receivedLength = 0;
      const chunks = [];

      while (true) {
        if (isPaused) {
          // 如果暂停了，就退出循环
          break;
        }

        const { done, value } = await reader.read();

        if (done) {
          break;
        }

        chunks.push(value);
        receivedLength += value.length;

        // 更新进度
        setDownloadProgress(Math.round((receivedLength / total) * 100));
      }

      if (!isPaused) {
        // 合并数据块
        const chunksAll = new Uint8Array(receivedLength);
        let position = 0;
        for (const chunk of chunks) {
          chunksAll.set(chunk, position);
          position += chunk.length;
        }

        // 创建Blob并下载
        const blob = new Blob([chunksAll]);
        const objectUrl = URL.createObjectURL(blob);

        const link = document.createElement('a');
        link.href = objectUrl;
        link.download = filename;
        document.body.appendChild(link);
        link.click();

        // 清理
        document.body.removeChild(link);
        URL.revokeObjectURL(objectUrl);

        setDownloadProgress(100);
      }
    } catch (error) {
      console.error('下载失败:', error);
      alert('下载失败，请重试');
    } finally {
      if (!isPaused) {
        setIsDownloading(false);
      }
    }
  }, [url, filename, fileSize, isPaused]);

  // 开始下载
  const startDownload = useCallback(() => {
    downloadWithProgress();
  }, [downloadWithProgress]);

  // 暂停下载
  const pauseDownload = useCallback(() => {
    setIsPaused(true);
  }, []);

  // 继续下载
  const resumeDownload = useCallback(() => {
    // 实际上，当前的实现不支持真正的断点续传
    // 这里只是重新开始下载
    downloadWithProgress();
  }, [downloadWithProgress]);

  return (
    <div className="file-downloader">
      <h2>文件下载</h2>

      <div className="download-info">
        <p>文件名: {filename}</p>
        {fileSize && <p>文件大小: {(fileSize / 1024 / 1024).toFixed(2)} MB</p>}
      </div>

      <div className="progress-container">
        <div className="progress-bar" style={{ width: `${downloadProgress}%` }}></div>
        <span className="progress-text">{downloadProgress}%</span>
      </div>

      <div className="button-group">
        {!isDownloading && !isPaused && <button onClick={startDownload}>开始下载</button>}

        {isDownloading && !isPaused && <button onClick={pauseDownload}>暂停下载</button>}

        {isPaused && <button onClick={resumeDownload}>继续下载</button>}
      </div>
    </div>
  );
};

export default FileDownloader;
```

## 四、使用 Web Worker 优化文件处理

对于大文件处理，特别是计算MD5等耗时操作，可以使用Web Worker避免阻塞主线程：

```js
// md5-worker.js
importScripts('https://cdnjs.cloudflare.com/ajax/libs/spark-md5/3.0.0/spark-md5.min.js');

self.onmessage = function (e) {
  const { file, chunkSize } = e.data;
  const blobSlice = File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice;
  const chunks = Math.ceil(file.size / chunkSize);
  let currentChunk = 0;
  const spark = new SparkMD5.ArrayBuffer();

  const fileReader = new FileReader();

  fileReader.onload = function (e) {
    spark.append(e.target.result);
    currentChunk++;

    if (currentChunk < chunks) {
      loadNext();
      // 报告进度
      self.postMessage({
        type: 'progress',
        progress: (currentChunk / chunks) * 100,
      });
    } else {
      const md5 = spark.end();
      self.postMessage({
        type: 'complete',
        md5: md5,
      });
    }
  };

  fileReader.onerror = function () {
    self.postMessage({
      type: 'error',
      error: 'FileReader error',
    });
  };

  function loadNext() {
    const start = currentChunk * chunkSize;
    const end = Math.min(start + chunkSize, file.size);
    fileReader.readAsArrayBuffer(blobSlice.call(file, start, end));
  }

  loadNext();
};
```

在 React 组件中使用 Web Worker：

```jsx
// 在组件中使用
const [md5Progress, setMd5Progress] = useState(0);

const calculateFileMD5WithWorker = useCallback((file) => {
  return new Promise((resolve, reject) => {
    const worker = new Worker('/md5-worker.js');

    worker.onmessage = (e) => {
      const { type, progress, md5, error } = e.data;

      if (type === 'progress') {
        setMd5Progress(progress);
      } else if (type === 'complete') {
        worker.terminate();
        resolve(md5);
      } else if (type === 'error') {
        worker.terminate();
        reject(error);
      }
    };

    worker.onerror = reject;

    worker.postMessage({
      file,
      chunkSize: 2097152, // 2MB
    });
  });
}, []);
```

## 五、服务端实现要点

虽然本文主要关注前端实现，但服务端的配合也很重要：

### 5.1 接受切片

```js
// Node.js Express 示例
const express = require('express');
const multer = require('multer');
const fs = require('fs');
const path = require('path');

const app = express();
const upload = multer({ dest: 'uploads/chunks' });

// 接收切片
app.post('/upload/chunk', upload.single('chunk'), (req, res) => {
  const { index, fileId, fileName, totalChunks } = req.body;
  const chunkDir = path.join(__dirname, 'uploads/chunks', fileId);

  // 确保目录存在
  if (!fs.existsSync(chunkDir)) {
    fs.mkdirSync(chunkDir, { recursive: true });
  }

  // 保存切片
  const chunkPath = path.join(chunkDir, index);
  fs.renameSync(req.file.path, chunkPath);

  // 记录已上传的切片
  const uploadInfoPath = path.join(chunkDir, 'upload_info.json');
  let uploadInfo = { fileName, totalChunks, uploadedChunks: [] };

  if (fs.existsSync(uploadInfoPath)) {
    uploadInfo = JSON.parse(fs.readFileSync(uploadInfoPath, 'utf-8'));
  }

  if (!uploadInfo.uploadedChunks.includes(Number(index))) {
    uploadInfo.uploadedChunks.push(Number(index));
  }

  fs.writeFileSync(uploadInfoPath, JSON.stringify(uploadInfo));

  res.json({ success: true });
});
```

### 5.2 获取已上传切片

```js
// 获取已上传的切片
app.get('/upload/chunks', (req, res) => {
  const { fileId } = req.query;
  const chunkDir = path.join(__dirname, 'uploads/chunks', fileId);
  const uploadInfoPath = path.join(chunkDir, 'upload_info.json');

  if (fs.existsSync(uploadInfoPath)) {
    const uploadInfo = JSON.parse(fs.readFileSync(uploadInfoPath, 'utf-8'));
    res.json({ uploadedChunks: uploadInfo.uploadedChunks });
  } else {
    res.json({ uploadedChunks: [] });
  }
});
```

### 5.3 合并切片

```js
// 合并切片
app.post('/upload/merge', (req, res) => {
  const { fileId, fileName, totalChunks } = req.body;
  const chunkDir = path.join(__dirname, 'uploads/chunks', fileId);
  const uploadDir = path.join(__dirname, 'uploads/files');
  const filePath = path.join(uploadDir, fileName);

  // 确保目录存在
  if (!fs.existsSync(uploadDir)) {
    fs.mkdirSync(uploadDir, { recursive: true });
  }

  // 创建写入流
  const writeStream = fs.createWriteStream(filePath);

  // 按顺序合并切片
  for (let i = 0; i < totalChunks; i++) {
    const chunkPath = path.join(chunkDir, i.toString());
    const chunkBuffer = fs.readFileSync(chunkPath);
    writeStream.write(chunkBuffer);
  }

  writeStream.end();

  writeStream.on('finish', () => {
    // 清理切片
    fs.rm(chunkDir, { recursive: true }, (err) => {
      if (err) {
        console.error('清理切片失败:', err);
      }
    });

    res.json({ success: true, url: `/uploads/files/${fileName}` });
  });

  writeStream.on('error', (err) => {
    console.error('合并文件失败:', err);
    res.status(500).json({ success: false, error: '合并文件失败' });
  });
});
```

### 5.4 支持Range请求的文件下载

```js
// 支持Range请求的文件下载
app.get('/download/:filename', (req, res) => {
  const filename = req.params.filename;
  const filePath = path.join(__dirname, 'uploads/files', filename);

  if (!fs.existsSync(filePath)) {
    return res.status(404).send('文件不存在');
  }

  const stat = fs.statSync(filePath);
  const fileSize = stat.size;
  const range = req.headers.range;

  if (range) {
    // 解析Range头
    const parts = range.replace(/bytes=/, '').split('-');
    const start = parseInt(parts[0], 10);
    const end = parts[1] ? parseInt(parts[1], 10) : fileSize - 1;
    const chunkSize = end - start + 1;

    const file = fs.createReadStream(filePath, { start, end });

    res.writeHead(206, {
      'Content-Range': `bytes ${start}-${end}/${fileSize}`,
      'Accept-Ranges': 'bytes',
      'Content-Length': chunkSize,
      'Content-Type': 'application/octet-stream',
      'Content-Disposition': `attachment; filename="${filename}"`,
    });

    file.pipe(res);
  } else {
    // 整个文件
    res.writeHead(200, {
      'Content-Length': fileSize,
      'Content-Type': 'application/octet-stream',
      'Content-Disposition': `attachment; filename="${filename}"`,
    });

    fs.createReadStream(filePath).pipe(res);
  }
});
```

## 六、性能优化与最佳实践

### 6.1 前端优化

1. 合理的切片大小：通常2MB-5MB是比较合适的切片大小，太小会增加请求数，太大可能导致单个请求超时。
2. 动态调整并发数：根据网络状况动态调整并发上传的切片数量：

```js
function getOptimalConcurrency() {
  // 根据网络状况动态调整
  const connection = navigator.connection || navigator.mozConnection || navigator.webkitConnection;
  if (!connection) return 3; // 默认值

  // 根据网络类型和带宽调整
  if (connection.type === 'wifi') return 6;
  if (connection.type === 'cellular' && connection.downlink < 1) return 2;

  return 3; // 默认值
}
```

3. 使用Web Worker：将MD5计算、文件切片等耗时操作放在Web Worker中执行，避免阻塞主线程。
4. 使用IndexedDB缓存切片：对于特别大的文件，可以使用IndexedDB临时存储切片，避免内存占用过大：

```js
// 存储切片到IndexedDB
async function storeChunk(fileId, index, chunk) {
  return new Promise((resolve, reject) => {
    const request = indexedDB.open('FileChunksDB', 1);

    request.onupgradeneeded = (e) => {
      const db = e.target.result;
      if (!db.objectStoreNames.contains('chunks')) {
        db.createObjectStore('chunks', { keyPath: 'id' });
      }
    };

    request.onsuccess = (e) => {
      const db = e.target.result;
      const transaction = db.transaction(['chunks'], 'readwrite');
      const store = transaction.objectStore('chunks');

      const item = {
        id: `${fileId}_${index}`,
        chunk,
        timestamp: Date.now(),
      };

      const storeRequest = store.put(item);
      storeRequest.onsuccess = () => resolve();
      storeRequest.onerror = () => reject(storeRequest.error);
    };

    request.onerror = () => reject(request.error);
  });
}
```

5. 预检查文件是否已上传：在开始上传前，先检查服务器是否已有相同MD5的文件，实现秒传功能。

### 6.2 服务端优化

1. 流式处理：使用流式处理而非一次性加载整个文件到内存。
2. 分布式存储：对于生产环境，考虑使用分布式存储系统如MinIO、S3等。
3. 定时清理过期切片：设置定时任务，清理长时间未完成上传的切片文件。
4. 限制上传大小和速率：根据服务器能力设置合理的限制，避免资源耗尽。

## 七、兼容性与降级处理

对于不支持现代API的浏览器，可以提供降级方案：

```js
// 检测浏览器能力
function checkBrowserCapabilities() {
  const capabilities = {
    fileSlice: !!(File.prototype.slice || File.prototype.mozSlice || File.prototype.webkitSlice),
    fileReader: !!window.FileReader,
    formData: !!window.FormData,
    progress: 'onprogress' in new XMLHttpRequest(),
    blob: !!window.Blob,
    arrayBuffer: !!window.ArrayBuffer,
    webWorker: !!window.Worker,
    indexedDB: !!window.indexedDB,
  };

  // 判断是否支持切片上传
  capabilities.sliceUpload = capabilities.fileSlice && capabilities.fileReader && capabilities.formData;

  // 判断是否支持高级功能
  capabilities.advancedFeatures = capabilities.sliceUpload && capabilities.webWorker && capabilities.indexedDB;

  return capabilities;
}

// 根据浏览器能力选择上传方法
function selectUploadMethod(file, options) {
  const capabilities = checkBrowserCapabilities();

  if (file.size <= 10 * 1024 * 1024) {
    // 小于10MB的文件直接上传
    return simpleUpload(file, options);
  } else if (capabilities.sliceUpload) {
    // 支持切片上传
    if (capabilities.advancedFeatures) {
      // 支持高级功能
      return advancedChunkUpload(file, options);
    } else {
      // 基本切片上传
      return basicChunkUpload(file, options);
    }
  } else {
    // 不支持切片，使用简单上传并提示用户
    alert('您的浏览器不支持大文件上传，可能会遇到超时问题');
    return simpleUpload(file, options);
  }
}
```

### 7.1 降级上传方案

```js
// 简单上传方案（不分片）
function simpleUpload(file, { onProgress, onSuccess, onError }) {
  const formData = new FormData();
  formData.append('file', file);

  const xhr = new XMLHttpRequest();

  if (xhr.upload && onProgress) {
    xhr.upload.onprogress = (e) => {
      if (e.lengthComputable) {
        const percent = Math.round((e.loaded / e.total) * 100);
        onProgress(percent);
      }
    };
  }

  xhr.onload = () => {
    if (xhr.status >= 200 && xhr.status < 300) {
      onSuccess && onSuccess(xhr.responseText);
    } else {
      onError && onError(new Error('Upload failed with status: ' + xhr.status));
    }
  };

  xhr.onerror = () => {
    onError && onError(new Error('Network error during upload'));
  };

  xhr.open('POST', '/upload', true);
  xhr.send(formData);

  return {
    abort: () => xhr.abort(),
  };
}
```

### 7.2 降级下载方案

```js
// 简单下载方案（不支持进度和断点续传）
function simpleDownload(url, filename) {
  // 方法1：使用a标签（最广泛支持）
  const link = document.createElement('a');
  link.href = url;
  link.download = filename || '';
  link.target = '_blank';
  document.body.appendChild(link);
  link.click();
  document.body.removeChild(link);

  // 方法2：使用iframe（兼容旧浏览器）
  /*
  const iframe = document.createElement('iframe');
  iframe.style.display = 'none';
  iframe.src = url;
  document.body.appendChild(iframe);
  setTimeout(() => {
    document.body.removeChild(iframe);
  }, 5000);
  */
}
```

## 八、安全性考虑

### 8.1 文件类型验证

```js
// 前端文件类型验证
function validateFileType(file, allowedTypes) {
  // 检查文件MIME类型
  if (allowedTypes && !allowedTypes.includes(file.type)) {
    return false;
  }

  // 检查文件扩展名
  const extension = file.name.split('.').pop().toLowerCase();
  const allowedExtensions = ['jpg', 'jpeg', 'png', 'pdf', 'doc', 'docx', 'xls', 'xlsx'];

  if (!allowedExtensions.includes(extension)) {
    return false;
  }

  return true;
}
```

### 8.2 文件大小限制

```js
// 前端文件大小验证
function validateFileSize(file, maxSize = 1024 * 1024 * 100) {
  // 默认100MB
  return file.size <= maxSize;
}
```

### 8.3 服务端安全措施

服务端应实施以下安全措施：

1. 文件类型验证：不仅检查扩展名，还应检查文件头信息
2. 病毒扫描：使用杀毒软件API扫描上传的文件
3. 存储隔离：将上传的文件存储在与应用程序隔离的位置
4. 访问控制：实施严格的访问控制，确保只有授权用户能访问文件
5. 文件重命名：避免使用用户提供的文件名，使用随机生成的名称

## 九、总结与展望

### 10.1 技术总结

本文详细介绍了大文件上传和下载的前端实现技术，主要包括：

1. 文件切片：将大文件分割成小块，分别上传
2. 断点续传：记录已上传的切片，支持中断后继续上传
3. 并发控制：限制同时上传的切片数量，避免资源耗尽
4. 进度监控：实时显示上传和下载进度
5. Web Worker：使用工作线程处理耗时操作，避免阻塞主线程
6. 流式下载：使用流式API处理大文件下载
7. 兼容性处理：为不同浏览器提供降级方案

### 10.2 未来展望

随着Web技术的发展，大文件处理将迎来更多创新：

1. WebTransport API：提供更可靠和高效的数据传输
2. WebCodecs API：在浏览器中进行高效的媒体处理
3. File System Access API：直接访问用户文件系统，提供更好的文件处理体验
4. Shared Array Buffer：在Web Worker之间共享内存，提高处理效率
5. WebAssembly：使用接近原生的性能处理大文件计算

### 10.3 最佳实践建议

1. 根据文件大小选择策略：小文件可以直接上传，大文件使用切片上传
2. 动态调整切片大小：根据网络状况和文件类型调整切片大小
3. 实现预上传检查：检查文件是否已存在，实现秒传功能
4. 提供友好的用户界面：显示详细的进度信息和操作选项
5. 做好错误处理：捕获并处理各种异常情况，提供重试机制
6. 考虑移动设备：移动设备上网络可能不稳定，需要更强的容错能力
